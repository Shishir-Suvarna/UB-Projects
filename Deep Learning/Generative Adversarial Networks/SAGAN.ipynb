{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cSAgan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O93sA_4-ESMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ab207cda-0c4b-412c-a809-59982778f6f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBk-geNarj8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the requirements\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Concatenate\n",
        "from numpy import asarray\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        "from keras.layers import Lambda\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from numpy import vstack\n",
        "from keras.datasets.cifar10 import load_data\n",
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import shuffle\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras.engine import *\n",
        "from keras.legacy import interfaces\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.utils.generic_utils import func_dump\n",
        "from keras.utils.generic_utils import func_load\n",
        "from keras.utils.generic_utils import deserialize_keras_object\n",
        "from keras.utils.generic_utils import has_arg\n",
        "from keras.utils import conv_utils\n",
        "from keras.legacy import interfaces\n",
        "from keras.layers import Dense, Conv1D, Conv2D, Conv3D, Conv2DTranspose, Embedding\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfRea2BxHZVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tesnorboard code snippet\n",
        "tensorboard = TensorBoard(\n",
        "  log_dir='log/sagan_log',\n",
        "  histogram_freq=0,\n",
        "  batch_size=128,\n",
        "  write_graph=True,\n",
        "  write_grads=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r219QZUxzie2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The CONVSN2D and DENSESN classes are passed to our discriminator hence it trains with spectralnormalization applied \n",
        "class DenseSN(Dense):\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[-1]\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                 initializer=initializers.RandomNormal(0, 1),\n",
        "                                 name='sn',\n",
        "                                 trainable=False)\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                 W_bar = K.reshape(W_bar, W_shape)  \n",
        "        output = K.dot(inputs, W_bar)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaL5Mkkxz3b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvSN2D(Conv2D):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        input_dim = input_shape[channel_axis]\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      name='kernel',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "            \n",
        "        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                         initializer=initializers.RandomNormal(0, 1),\n",
        "                         name='sn',\n",
        "                         trainable=False)\n",
        "        \n",
        "        # Set input spec.\n",
        "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                    axes={channel_axis: input_dim})\n",
        "        self.built = True\n",
        "    def call(self, inputs, training=None):\n",
        "        def _l2normalize(v, eps=1e-12):\n",
        "            return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "        def power_iteration(W, u):\n",
        "            #Accroding the paper, we only need to do power iteration one time.\n",
        "            _u = u\n",
        "            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "            _u = _l2normalize(K.dot(_v, W))\n",
        "            return _u, _v\n",
        "        #Spectral Normalization\n",
        "        W_shape = self.kernel.shape.as_list()\n",
        "        #Flatten the Tensor\n",
        "        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "        _u, _v = power_iteration(W_reshaped, self.u)\n",
        "        #Calculate Sigma\n",
        "        sigma=K.dot(_v, W_reshaped)\n",
        "        sigma=K.dot(sigma, K.transpose(_u))\n",
        "        #normalize it\n",
        "        W_bar = W_reshaped / sigma\n",
        "        #reshape weight tensor\n",
        "        if training in {0, False}:\n",
        "            W_bar = K.reshape(W_bar, W_shape)\n",
        "        else:\n",
        "            with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                W_bar = K.reshape(W_bar, W_shape)\n",
        "                \n",
        "        outputs = K.conv2d(\n",
        "                inputs,\n",
        "                W_bar,\n",
        "                strides=self.strides,\n",
        "                padding=self.padding,\n",
        "                data_format=self.data_format,\n",
        "                dilation_rate=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            outputs = K.bias_add(\n",
        "                outputs,\n",
        "                self.bias,\n",
        "                data_format=self.data_format)\n",
        "        if self.activation is not None:\n",
        "            return self.activation(outputs)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjjyvB5rWhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conv used to reshape our data\n",
        "def conv(x, channels, kernel=[1,1,1,1], stride=1):\n",
        "  print(x.shape)\n",
        "  print(kernel)\n",
        "   \n",
        "\n",
        "  filter_size = 4 \n",
        "  input_channels = channels\n",
        "  output_filters = channels\n",
        "\n",
        "  x = tf.nn.conv2d(x, filters=tf.Variable(tf.truncated_normal([filter_size, filter_size, input_channels, output_filters], stddev=0.5)), strides=[1,1,1,1] , padding='SAME')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAF2u4MXroKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention(x):\n",
        "  f = conv(x, 128 // 8, kernel=1, stride=1) # [bs, h, w, c']\n",
        "  g = conv(x, 128 // 8, kernel=1, stride=1) # [bs, h, w, c']\n",
        "  h = conv(x, 128, kernel=1, stride=1) # [bs, h, w, c]\n",
        "\n",
        "  s = tf.matmul(g, f, transpose_b=True) # # [bs, N, N]\n",
        "  beta = tf.nn.softmax(s)  # attention map\n",
        "  o = tf.matmul(beta, h) # [bs, N, C]\n",
        "\n",
        "  with tf.variable_scope(\"gamma\", reuse=tf.AUTO_REUSE):\n",
        "    gamma = tf.get_variable(\"gamma\", [1], initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "  o = conv(o, 128, kernel=1, stride=1)\n",
        "  x = gamma * o + x\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0dO6DFvRw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training the disc. using categorical_hinge as loss and passing our convolution layers to facilitate upsampling/downsampling\n",
        "# adding our attention layer\n",
        "def define_discriminator(in_shape=(32,32,3), n_classes=10):\n",
        "  in_label = Input(shape=(1,))\n",
        "  li = Embedding(n_classes, 50)(in_label)\n",
        "\n",
        "  n_nodes = in_shape[0] * in_shape[1]\n",
        "  li = DenseSN(n_nodes)(li)\n",
        "  li = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
        "  in_image = Input(shape=in_shape)\n",
        "  merge = Concatenate()([in_image, li])\n",
        "  fe = ConvSN2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Lambda(attention)(fe)\n",
        "  fe = ConvSN2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "  fe = LeakyReLU(alpha=0.2)(fe)\n",
        "  fe = Flatten()(fe)\n",
        "  fe = Dropout(0.4)(fe)\n",
        "  out_layer = DenseSN(1, activation='sigmoid')(fe)\n",
        "  model = Model([in_image, in_label], out_layer)\n",
        "  model.compile(loss='categorical_hinge', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfAtZEhgvWlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding attention layer using lambda\n",
        "def define_generator(latent_dim, n_classes=10):\n",
        "  in_label = Input(shape=(1,))\n",
        "  li = Embedding(n_classes, 50)(in_label)\n",
        "  n_nodes = 8 * 8\n",
        "  li = Dense(n_nodes)(li)\n",
        "  li = Reshape((8, 8, 1))(li)\n",
        "  in_lat = Input(shape=(latent_dim,))\n",
        "  n_nodes = 128 * 8 * 8\n",
        "  gen = Dense(n_nodes)(in_lat)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  gen = Reshape((8, 8, 128))(gen)\n",
        "  merge = Concatenate()([gen, li])\n",
        "  gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  gen = Lambda(attention)(gen)\n",
        "  gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  out_layer = Conv2D(3, (3,3), activation='tanh', padding='same')(gen)\n",
        "  model = Model([in_lat, in_label], out_layer)\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU26jtW_vWzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\tgen_noise, gen_label = g_model.input\n",
        "\tgen_output = g_model.output\n",
        "\tgan_output = d_model([gen_output, gen_label])\n",
        "\tmodel = Model([gen_noise, gen_label], gan_output)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTScGy1HMHg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard.set_model(define_gan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhBEMH2evW3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following functions are common to the DCGAN and SAGAN implementations\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "  (trainX, trainy), (_, _) = load_data()\n",
        "  X = trainX\n",
        "  X = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return [X, trainy]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN6pwY1svW7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\timages, labels = dataset\n",
        "\tix = randint(0, images.shape[0], n_samples)\n",
        "\tX, labels = images[ix], labels[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn [X, labels], y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKl7j3ervk0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\tlabels = randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTv0MsyevhTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "\timages = generator.predict([z_input, labels_input])\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn [images, labels_input], y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbEwFeLxCZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\tlabels = randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]\n",
        "\n",
        "def save_plot(examples, n):\n",
        "\tfor i in range(n * n):\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\tpyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktNTXLto0mot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "\n",
        "def calculate_fid(model, images1, images2):\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cMXomRsvhWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=50, n_batch=128):\n",
        "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\tfor i in range(n_epochs):\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t[X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "\t\t\t[X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
        "\t\t\t[z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
        "\n",
        "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\tg_model.save('cgan_generator.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvkfTMhvhQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 100\n",
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "dataset = load_real_samples()\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3VXeNv_Sr3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of loading the generator model and generating images\n",
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        " \n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\tlabels = randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mt7UDZWWyB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_plot(examples, epoch, n=8):\n",
        "\n",
        "  examples = (examples+1)/2.0\n",
        "\n",
        "  for i in range(n*n):\n",
        "    pyplot.subplot(n,n,1+i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i])\n",
        "\n",
        "  pyplot.savefig('drive/My Drive/sagan_grids/generated_plote%05d.png' % (epoch+1))\n",
        "  pyplot.close()\n",
        "\n",
        "  model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "  (_,_),(images1, _) = load_data()\n",
        "  images2 = examples\n",
        "  shuffle(images1)\n",
        "  images1 = images1[:1000]\n",
        "  print('Loaded', images1.shape, images2.shape)\n",
        "  images1 = images1.astype('float32')\n",
        "  images1 = (images1 - 127.5) / 127.5\n",
        "  images2 = images2.astype('float32')\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  images2 = scale_images(images2, (299,299,3))\n",
        "  print('Scaled', images1.shape, images2.shape)\n",
        "  fid = calculate_fid(model, images1, images2)\n",
        "  print('FID: %.3f' % fid)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1yWQpSvS225",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "model = load_model('cgan_generator.h5',custom_objects={'conv':conv, 'tf':tf})\n",
        "latent_points, labels = generate_latent_points(100, 100)\n",
        "labels = asarray([x for _ in range(10) for x in range(10)])\n",
        "X  = model.predict([latent_points, labels])\n",
        "X = (X + 1) / 2.0\n",
        "save_plot(X, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}