{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPIoOwU0lMw4",
        "colab_type": "code",
        "outputId": "a5a058fe-78f5-4650-ca67-382c609db8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Mount Google Drive onto Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hObf3u3gdVpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import shuffle\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "from keras.datasets import cifar10\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysr0qR0qC9Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this part is used to specify important parameters for TensorBoard such as \n",
        "# the batch size and which directory to store the \"Event files\" which are then used for TensorBoard visualization\n",
        "tensorboard = TensorBoard(\n",
        "  log_dir='log/dcgan_log',\n",
        "  histogram_freq=0,\n",
        "  batch_size=128,\n",
        "  write_graph=True,\n",
        "  write_grads=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r009oxYgdgxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We first develop a generator model which is composed of multiple \"Sequential\" layers.\n",
        "# The generator takes in a latent space as input(a Gaussian of Random numbers). We upsample the image consecutively\n",
        "# into a higher resolution version of the image\n",
        "def def_gen(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\tn_nodes = 256 * 4 * 4\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((4, 4, 256)))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx_O5Fffdgd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we define a Discriminator in our architecture. The Discriminator takes an input with shape 32*32*3 \n",
        "# where 32*32 are length and breadth and 3 is the number of color channels(RGB). \n",
        "# There are a number of convolutional layers in the model which are then compiled. The loss is set to be \"Binary CrossEntropy\".\n",
        "def define_discriminator(in_shape=(32,32,3)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFNU_qL1dg0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to train the generator, we need to combine the generator and the discriminator into one model.\n",
        "# The generator model output(the fake images), are set to real(class 1) and fed to the discriminator, \n",
        "# Whe the Discriminator classifies the images as fake, the resulting loss is then used to update the Generator weights and train it.\n",
        "# Note that the Discriminator is set to be \"untrainable\" when training the Generator because otherwise the Discriminator \n",
        "# is trained both independently as well as during the generator training hence making it better \n",
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv_N5H9GJSqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# linking our combined GAN model to TensorBoard\n",
        "tensorboard.set_model(define_gan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiQ0ZPUkdg2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Images from the training set of CIFAR10 are loaded and in order to normalize the images effectively, \n",
        "# the input is converted into float values\n",
        "def load_real_samples():\n",
        "\t(trainX, _), (_, _) = load_data()\n",
        "\tX = trainX.astype('float32')\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E8lp_W9dg6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose at Random values from the Training samples and get the class labels (Y) for the samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_FeLrjOdg9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initially, the generator takes in what is essentially noise as input and generates an images of (32*32*3).\n",
        "# Points from a Latent vector space are chosen at random \n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaF0hJDrePdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takr the latent space as input and generate fake samples from that\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\tX = g_model.predict(x_input)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktNTXLto0mot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaling of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "# Calculate the FID between our \n",
        "def calculate_fid(model, images1, images2):\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHK04atLFcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a grid plot of size 8x8 and save the plots periodically to drive\n",
        "def save_plot(examples, epoch, n=8):\n",
        "\n",
        "  examples = (examples+1)/2.0\n",
        "\n",
        "  for i in range(n*n):\n",
        "    pyplot.subplot(n,n,1+i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i])\n",
        "\n",
        "  pyplot.savefig('drive/My Drive/saved_grids/generated_plote%05d.png' % (epoch+1))\n",
        "  pyplot.close()\n",
        "\n",
        "#   prepare the two sets of images against which FID is going to be computed. We take images1 from CIFAR10 and take the remaining from the examples we generate   \n",
        "  model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
        "  (_,_),(images1, _) = load_data()\n",
        "  images2 = examples\n",
        "  shuffle(images1)\n",
        "  images1 = images1[:1000]\n",
        "  print('Loaded', images1.shape, images2.shape)\n",
        "  images1 = images1.astype('float32')\n",
        "  images1 = (images1 - 127.5) / 127.5\n",
        "  images2 = images2.astype('float32')\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  images2 = scale_images(images2, (299,299,3))\n",
        "  print('Scaled', images1.shape, images2.shape)\n",
        "\n",
        "  fid = calculate_fid(model, images1, images2)\n",
        "  print('FID: %.3f' % fid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7G0tA-ZePaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model \n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=1500):\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\tfilename = 'generator_model_%05d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY27mX2Qebe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the train function trains the generator and discrminator by selecting the real images for the discriminator and prepare the input for generator from space\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=128):\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  for i in range(n_epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "      d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "      X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)      \n",
        "\n",
        "      print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "        (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "    tensorboard.on_epoch_end(n_epochs, {\"D_real_loss\":d_loss1 ,\"D_fake_loss\":d_loss2,\"GAN_loss\":g_loss})\n",
        "\n",
        "\n",
        "    if (i+1) % 2 == 0:\n",
        "      summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfqGhlLWebiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specifying our models(both generator and discriminator)  \n",
        "latent_dim = 100\n",
        "d_model = define_discriminator()\n",
        "g_model = def_gen(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "dataset = load_real_samples()\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}