{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical \n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "trainingdata = np.asmatrix(training_data[0])\n",
    "trainingtarget1 = np.asmatrix(training_data[1])\n",
    "testdata = np.asarray(test_data[0])\n",
    "testtarget = np.asarray(test_data[1])\n",
    "valdata = np.asarray(validation_data[0])\n",
    "valtarget = np.asarray(validation_data[1])\n",
    "\n",
    "print(trainingdata.shape)\n",
    "print(testdata.shape)\n",
    "print(valdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 784)\n",
      "(19999,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(USPSMat))\n",
    "print(np.shape(USPSTar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Multi-class Logistic Regression With Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "r,c = (np.asmatrix(trainingdata)).shape\n",
    "print((np.asmatrix(trainingdata)).shape)\n",
    "\n",
    "trainingtarget = to_categorical(trainingtarget1, nb_classes)\n",
    "trainingtarget = trainingtarget.reshape(50000,10)\n",
    "\n",
    "def softmax(data,w):\n",
    "    x = np.dot(data,w)\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "    return e_x/e_x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.005\n",
    "nb_classes   = 10\n",
    "\n",
    "W_Now = np.ones((c,10))\n",
    "\n",
    "#<-------------------------------------------------Test Data--------------------------------------------------------->#\n",
    "\n",
    "for i in range(0,50000):\n",
    "    \n",
    "    t_data        = trainingdata[i].reshape(784,1)    \n",
    "    y             = softmax(t_data.T,W_Now)\n",
    "    tr = trainingtarget[i].reshape(1,10)\n",
    "    Target_new    = np.subtract(y,tr)\n",
    "    Delta_E       = np.dot(t_data,Target_new)\n",
    "    Delta_W       = np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = np.subtract(W_Now,Delta_W)\n",
    "    W_Now         = W_T_Next\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------------------------------------Test Data--------------------------------------------------------->#\n",
    "\n",
    "counter = 0\n",
    "y_ts           = softmax(testdata,W_Now)\n",
    "TR_TEST_OUT_M = np.argmax(y_ts, axis=1)\n",
    "TR_OUT      = np.transpose(testtarget)\n",
    "\n",
    "for i in range (0,10000):\n",
    "    if(TR_TEST_OUT_M[i] == TR_OUT[i]):\n",
    "        counter+=1\n",
    "acc_ts = (counter/10000)*100\n",
    "\n",
    "#<----------------------------------------------Vadlidation Data------------------------------------------------------>#\n",
    "\n",
    "counter = 0\n",
    "y           = softmax(valdata,W_Now)\n",
    "VL_TEST_OUT_M = np.argmax(y, axis=1)\n",
    "VL_OUT      = np.transpose(valtarget)\n",
    "\n",
    "for i in range (0,len(valtarget)):\n",
    "    if(VL_TEST_OUT_M[i] == VL_OUT[i]):\n",
    "        counter+=1\n",
    "acc_vl = (counter/len(valtarget))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy -------->  90.84\n",
      "Validation Accuracy ----->  91.33\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy -------->  \"+ str(np.around(acc_ts,4)))\n",
    "print(\"Validation Accuracy ----->  \"+ str(np.around(acc_vl,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 955,    0,    1,    4,    0,    5,    9,    1,    5,    0],\n",
       "       [   0, 1113,    0,    5,    0,    3,    4,    2,    8,    0],\n",
       "       [   9,    9,  881,   31,   11,    3,   13,   24,   43,    8],\n",
       "       [   2,    0,   11,  927,    0,   37,    1,   12,   12,    8],\n",
       "       [   2,    4,    4,    1,  887,    1,   12,    4,   10,   57],\n",
       "       [   8,    5,    1,   44,    6,  775,   10,    9,   26,    8],\n",
       "       [  12,    3,    3,    3,    8,   29,  892,    3,    5,    0],\n",
       "       [   2,   14,   19,    8,    5,    0,    0,  951,    3,   26],\n",
       "       [   3,   10,    4,   46,    7,   55,   12,   16,  808,   13],\n",
       "       [   8,    8,    2,   13,   20,   19,    0,   40,    4,  895]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = testtarget\n",
    "y_pred = TR_TEST_OUT_M\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.95      0.98      0.97      1135\n",
      "           2       0.95      0.85      0.90      1032\n",
      "           3       0.86      0.92      0.89      1010\n",
      "           4       0.94      0.90      0.92       982\n",
      "           5       0.84      0.87      0.85       892\n",
      "           6       0.94      0.93      0.93       958\n",
      "           7       0.90      0.93      0.91      1028\n",
      "           8       0.87      0.83      0.85       974\n",
      "           9       0.88      0.89      0.88      1009\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testtarget, TR_TEST_OUT_M)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist1 = np.asarray(VL_TEST_OUT_M) #-------------------------------> MNIST prediction 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on USPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "y           = softmax(USPSMat,W_Now)\n",
    "USPS_TEST_OUT_U = np.argmax(y, axis=1)\n",
    "USPS_OUT      = np.transpose(USPSTar)\n",
    "\n",
    "for i in range (0,len(USPSTar)):\n",
    "    if(USPS_TEST_OUT_U[i] == USPS_OUT[i]):\n",
    "        counter+=1\n",
    "acc_usps = (counter/len(USPSTar))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy on USPS -------->  34.9467\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy on USPS -------->  \"+ str(np.around(acc_usps,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 563,    4,  255,   84,  167,  238,   95,   88,  146,  360],\n",
       "       [ 159,  356,  161,  341,  153,  108,   29,  464,  202,   27],\n",
       "       [ 173,   21, 1101,  233,   37,  149,   87,   85,   81,   32],\n",
       "       [  59,    2,  108, 1337,    3,  331,    3,   67,   56,   34],\n",
       "       [  64,   81,   32,   75,  833,  169,   46,  210,  321,  169],\n",
       "       [ 134,   19,  162,  210,   24, 1232,   82,   72,   48,   17],\n",
       "       [ 262,   10,  334,  147,   65,  396,  677,   26,   41,   42],\n",
       "       [ 161,  200,  216,  523,   58,  116,   22,  368,  276,   60],\n",
       "       [ 222,   32,  116,  248,   76,  737,  102,   56,  343,   68],\n",
       "       [  30,  144,  111,  526,   88,  112,   14,  460,  336,  179]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = USPSTar\n",
    "y_pred1 = USPS_TEST_OUT_U\n",
    "confusion_matrix(y_true, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.29      2000\n",
      "           1       0.41      0.18      0.25      2000\n",
      "           2       0.42      0.55      0.48      1999\n",
      "           3       0.36      0.67      0.47      2000\n",
      "           4       0.55      0.42      0.48      2000\n",
      "           5       0.34      0.62      0.44      2000\n",
      "           6       0.59      0.34      0.43      2000\n",
      "           7       0.19      0.18      0.19      2000\n",
      "           8       0.19      0.17      0.18      2000\n",
      "           9       0.18      0.09      0.12      2000\n",
      "\n",
      "   micro avg       0.35      0.35      0.35     19999\n",
      "   macro avg       0.35      0.35      0.33     19999\n",
      "weighted avg       0.35      0.35      0.33     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(USPSTar, USPS_TEST_OUT_U)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps1 = np.asarray(USPS_TEST_OUT_U) #-------------------------------> USPS prediction 1\n",
    "usps1 = usps1.reshape(19999,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdata = np.asmatrix(training_data[0])\n",
    "trainingtarget = np.asarray(training_data[1])\n",
    "\n",
    "valdata = np.asmatrix(validation_data[0])\n",
    "valtarget = np.asarray(validation_data[1])\n",
    "\n",
    "testdata = np.asmatrix(test_data[0])\n",
    "testtarget = np.asarray(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(labels):\n",
    "    return np_utils.to_categorical(np.array(labels),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size =784\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer_nodes  = 256\n",
    "third_dense_layer_nodes  = 10\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(third_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adamax',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.9598 - acc: 0.4417 - val_loss: 1.6779 - val_acc: 0.5928\n",
      "Epoch 2/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.5324 - acc: 0.4959 - val_loss: 1.2945 - val_acc: 0.5968\n",
      "Epoch 3/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.2807 - acc: 0.5028 - val_loss: 1.0582 - val_acc: 0.6023\n",
      "Epoch 4/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.1502 - acc: 0.5080 - val_loss: 0.9232 - val_acc: 0.6099\n",
      "Epoch 5/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.0774 - acc: 0.5135 - val_loss: 0.8394 - val_acc: 0.6256\n",
      "Epoch 6/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.0390 - acc: 0.5217 - val_loss: 0.7908 - val_acc: 0.6266\n",
      "Epoch 7/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.0133 - acc: 0.5337 - val_loss: 0.7571 - val_acc: 0.6648\n",
      "Epoch 8/10000\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.9856 - acc: 0.5577 - val_loss: 0.7195 - val_acc: 0.6964\n",
      "Epoch 9/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.9593 - acc: 0.5727 - val_loss: 0.6847 - val_acc: 0.7203\n",
      "Epoch 10/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.9426 - acc: 0.5858 - val_loss: 0.6586 - val_acc: 0.7263\n",
      "Epoch 11/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.9172 - acc: 0.6024 - val_loss: 0.6314 - val_acc: 0.7563\n",
      "Epoch 12/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.8998 - acc: 0.6184 - val_loss: 0.6047 - val_acc: 0.7806\n",
      "Epoch 13/10000\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.8724 - acc: 0.6344 - val_loss: 0.5838 - val_acc: 0.7918\n",
      "Epoch 14/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.8624 - acc: 0.6381 - val_loss: 0.5581 - val_acc: 0.7956\n",
      "Epoch 15/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.8467 - acc: 0.6433 - val_loss: 0.5352 - val_acc: 0.8017\n",
      "Epoch 16/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.8343 - acc: 0.6452 - val_loss: 0.5208 - val_acc: 0.8091\n",
      "Epoch 17/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.8165 - acc: 0.6565 - val_loss: 0.5085 - val_acc: 0.8323\n",
      "Epoch 18/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.8060 - acc: 0.6710 - val_loss: 0.4969 - val_acc: 0.8513\n",
      "Epoch 19/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.7916 - acc: 0.6828 - val_loss: 0.4762 - val_acc: 0.8737\n",
      "Epoch 20/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.7499 - acc: 0.7034 - val_loss: 0.4376 - val_acc: 0.8890\n",
      "Epoch 21/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.7233 - acc: 0.7124 - val_loss: 0.4090 - val_acc: 0.9122\n",
      "Epoch 22/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.6940 - acc: 0.7358 - val_loss: 0.3738 - val_acc: 0.9539\n",
      "Epoch 23/10000\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.6513 - acc: 0.7616 - val_loss: 0.3384 - val_acc: 0.9667\n",
      "Epoch 24/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.6222 - acc: 0.7699 - val_loss: 0.3072 - val_acc: 0.9680\n",
      "Epoch 25/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.5986 - acc: 0.7723 - val_loss: 0.2777 - val_acc: 0.9714\n",
      "Epoch 26/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.5702 - acc: 0.7788 - val_loss: 0.2513 - val_acc: 0.9724\n",
      "Epoch 27/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.5508 - acc: 0.7834 - val_loss: 0.2321 - val_acc: 0.9727\n",
      "Epoch 28/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.5348 - acc: 0.7861 - val_loss: 0.2155 - val_acc: 0.9746\n",
      "Epoch 29/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.5256 - acc: 0.7843 - val_loss: 0.2056 - val_acc: 0.9740\n",
      "Epoch 30/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.5098 - acc: 0.7863 - val_loss: 0.1939 - val_acc: 0.9752\n",
      "Epoch 31/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.5046 - acc: 0.7844 - val_loss: 0.1833 - val_acc: 0.9766\n",
      "Epoch 32/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4889 - acc: 0.7907 - val_loss: 0.1778 - val_acc: 0.9751\n",
      "Epoch 33/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.4859 - acc: 0.7897 - val_loss: 0.1706 - val_acc: 0.9764\n",
      "Epoch 34/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.4798 - acc: 0.7911 - val_loss: 0.1670 - val_acc: 0.9761\n",
      "Epoch 35/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4719 - acc: 0.7922 - val_loss: 0.1612 - val_acc: 0.9771\n",
      "Epoch 36/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.4653 - acc: 0.7936 - val_loss: 0.1572 - val_acc: 0.9772\n",
      "Epoch 37/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4602 - acc: 0.7985 - val_loss: 0.1547 - val_acc: 0.9773\n",
      "Epoch 38/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4563 - acc: 0.8054 - val_loss: 0.1537 - val_acc: 0.9766\n",
      "Epoch 39/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4522 - acc: 0.8077 - val_loss: 0.1516 - val_acc: 0.9779\n",
      "Epoch 40/10000\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.4432 - acc: 0.8118 - val_loss: 0.1460 - val_acc: 0.9770\n",
      "Epoch 41/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.4411 - acc: 0.8111 - val_loss: 0.1441 - val_acc: 0.9777\n",
      "Epoch 42/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.4434 - acc: 0.8060 - val_loss: 0.1446 - val_acc: 0.9781\n",
      "Epoch 43/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4448 - acc: 0.8064 - val_loss: 0.1417 - val_acc: 0.9785\n",
      "Epoch 44/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4364 - acc: 0.8079 - val_loss: 0.1384 - val_acc: 0.9785\n",
      "Epoch 45/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4285 - acc: 0.8107 - val_loss: 0.1381 - val_acc: 0.9776\n",
      "Epoch 46/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.4224 - acc: 0.8141 - val_loss: 0.1397 - val_acc: 0.9784\n",
      "Epoch 47/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.4231 - acc: 0.8272 - val_loss: 0.1384 - val_acc: 0.9792\n",
      "Epoch 48/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.4128 - acc: 0.8353 - val_loss: 0.1394 - val_acc: 0.9779\n",
      "Epoch 49/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.4097 - acc: 0.8375 - val_loss: 0.1382 - val_acc: 0.9785\n",
      "Epoch 50/10000\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.4004 - acc: 0.8411 - val_loss: 0.1372 - val_acc: 0.9795\n",
      "Epoch 51/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.3981 - acc: 0.8408 - val_loss: 0.1382 - val_acc: 0.9789\n",
      "Epoch 52/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.3950 - acc: 0.8410 - val_loss: 0.1333 - val_acc: 0.9786\n",
      "Epoch 53/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.3865 - acc: 0.8440 - val_loss: 0.1309 - val_acc: 0.9784\n",
      "Epoch 54/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.3850 - acc: 0.8435 - val_loss: 0.1299 - val_acc: 0.9788\n",
      "Epoch 55/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.3812 - acc: 0.8434 - val_loss: 0.1272 - val_acc: 0.9791\n",
      "Epoch 56/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.3689 - acc: 0.8485 - val_loss: 0.1267 - val_acc: 0.9784\n",
      "Epoch 57/10000\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3695 - acc: 0.8478 - val_loss: 0.1266 - val_acc: 0.9792\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.3630 - acc: 0.8507 - val_loss: 0.1260 - val_acc: 0.9784\n",
      "Epoch 59/10000\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3600 - acc: 0.8528 - val_loss: 0.1234 - val_acc: 0.9796\n",
      "Epoch 60/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.3616 - acc: 0.8525 - val_loss: 0.1257 - val_acc: 0.9789\n",
      "Epoch 61/10000\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3481 - acc: 0.8587 - val_loss: 0.1243 - val_acc: 0.9795\n",
      "Epoch 62/10000\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.3449 - acc: 0.8639 - val_loss: 0.1276 - val_acc: 0.9786\n",
      "Epoch 63/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.3319 - acc: 0.8739 - val_loss: 0.1208 - val_acc: 0.9796\n",
      "Epoch 64/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.3169 - acc: 0.8840 - val_loss: 0.1169 - val_acc: 0.9806\n",
      "Epoch 65/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.3092 - acc: 0.8886 - val_loss: 0.1121 - val_acc: 0.9798\n",
      "Epoch 66/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.3021 - acc: 0.8936 - val_loss: 0.1085 - val_acc: 0.9810\n",
      "Epoch 67/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.2909 - acc: 0.8987 - val_loss: 0.1054 - val_acc: 0.9808\n",
      "Epoch 68/10000\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.2915 - acc: 0.8973 - val_loss: 0.1041 - val_acc: 0.9804\n",
      "Epoch 69/10000\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.2836 - acc: 0.8992 - val_loss: 0.1038 - val_acc: 0.9799\n",
      "Epoch 70/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.2920 - acc: 0.8944 - val_loss: 0.1034 - val_acc: 0.9802\n",
      "Epoch 71/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2796 - acc: 0.8990 - val_loss: 0.1019 - val_acc: 0.9802\n",
      "Epoch 72/10000\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.2791 - acc: 0.8974 - val_loss: 0.1035 - val_acc: 0.9798\n",
      "Epoch 73/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2778 - acc: 0.8963 - val_loss: 0.1022 - val_acc: 0.9798\n",
      "Epoch 74/10000\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.2725 - acc: 0.8988 - val_loss: 0.1004 - val_acc: 0.9818\n",
      "Epoch 75/10000\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.2664 - acc: 0.9015 - val_loss: 0.1027 - val_acc: 0.9801\n",
      "Epoch 76/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.2650 - acc: 0.9028 - val_loss: 0.1025 - val_acc: 0.9806\n",
      "Epoch 77/10000\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2621 - acc: 0.9052 - val_loss: 0.1040 - val_acc: 0.9795\n",
      "Epoch 78/10000\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.2563 - acc: 0.9084 - val_loss: 0.1028 - val_acc: 0.9806\n",
      "Epoch 79/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2549 - acc: 0.9098 - val_loss: 0.1002 - val_acc: 0.9805\n",
      "Epoch 80/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2456 - acc: 0.9130 - val_loss: 0.0987 - val_acc: 0.9808\n",
      "Epoch 81/10000\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.2451 - acc: 0.9117 - val_loss: 0.0970 - val_acc: 0.9814\n",
      "Epoch 82/10000\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.2344 - acc: 0.9150 - val_loss: 0.0984 - val_acc: 0.9801\n",
      "Epoch 83/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.2402 - acc: 0.9125 - val_loss: 0.0962 - val_acc: 0.9802\n",
      "Epoch 84/10000\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.2358 - acc: 0.9144 - val_loss: 0.0954 - val_acc: 0.9810\n",
      "Epoch 85/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2333 - acc: 0.9128 - val_loss: 0.0971 - val_acc: 0.9802\n",
      "Epoch 86/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.2265 - acc: 0.9161 - val_loss: 0.0964 - val_acc: 0.9803\n",
      "Epoch 87/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.2260 - acc: 0.9155 - val_loss: 0.0977 - val_acc: 0.9804\n",
      "Epoch 88/10000\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.2196 - acc: 0.9185 - val_loss: 0.0967 - val_acc: 0.9805\n",
      "Epoch 89/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2277 - acc: 0.9145 - val_loss: 0.0961 - val_acc: 0.9812\n",
      "Epoch 90/10000\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.2203 - acc: 0.9159 - val_loss: 0.0960 - val_acc: 0.9817\n",
      "Epoch 91/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.2186 - acc: 0.9165 - val_loss: 0.0974 - val_acc: 0.9806\n",
      "Epoch 92/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2170 - acc: 0.9172 - val_loss: 0.0983 - val_acc: 0.9807\n",
      "Epoch 93/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.2183 - acc: 0.9160 - val_loss: 0.0973 - val_acc: 0.9809\n",
      "Epoch 94/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.2187 - acc: 0.9150 - val_loss: 0.0984 - val_acc: 0.9803\n",
      "Epoch 95/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2149 - acc: 0.9169 - val_loss: 0.0962 - val_acc: 0.9810\n",
      "Epoch 96/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.2121 - acc: 0.9164 - val_loss: 0.0974 - val_acc: 0.9811\n",
      "Epoch 97/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.2098 - acc: 0.9183 - val_loss: 0.0953 - val_acc: 0.9813\n",
      "Epoch 98/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2073 - acc: 0.9188 - val_loss: 0.0972 - val_acc: 0.9809\n",
      "Epoch 99/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.2158 - acc: 0.9147 - val_loss: 0.0973 - val_acc: 0.9805\n",
      "Epoch 100/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.2064 - acc: 0.9176 - val_loss: 0.0969 - val_acc: 0.9816\n",
      "Epoch 101/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2061 - acc: 0.9193 - val_loss: 0.0980 - val_acc: 0.9812\n",
      "Epoch 102/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2085 - acc: 0.9171 - val_loss: 0.0978 - val_acc: 0.9804\n",
      "Epoch 103/10000\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.2005 - acc: 0.9216 - val_loss: 0.0980 - val_acc: 0.9806\n",
      "Epoch 104/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.2041 - acc: 0.9202 - val_loss: 0.1000 - val_acc: 0.9804\n",
      "Epoch 105/10000\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.2016 - acc: 0.9207 - val_loss: 0.0985 - val_acc: 0.9816\n",
      "Epoch 106/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.2014 - acc: 0.9211 - val_loss: 0.0978 - val_acc: 0.9810\n",
      "Epoch 107/10000\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.1953 - acc: 0.9226 - val_loss: 0.0968 - val_acc: 0.9818\n",
      "Epoch 108/10000\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.1956 - acc: 0.9227 - val_loss: 0.1015 - val_acc: 0.9791\n",
      "Epoch 109/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1911 - acc: 0.9259 - val_loss: 0.1015 - val_acc: 0.9813\n",
      "Epoch 110/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1917 - acc: 0.9250 - val_loss: 0.0992 - val_acc: 0.9807\n",
      "Epoch 111/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1955 - acc: 0.9236 - val_loss: 0.1009 - val_acc: 0.9814\n",
      "Epoch 112/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1884 - acc: 0.9265 - val_loss: 0.0996 - val_acc: 0.9802\n",
      "Epoch 113/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.1891 - acc: 0.9253 - val_loss: 0.0993 - val_acc: 0.9806\n",
      "Epoch 114/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1946 - acc: 0.9227 - val_loss: 0.1019 - val_acc: 0.9802\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1901 - acc: 0.9239 - val_loss: 0.0995 - val_acc: 0.9806\n",
      "Epoch 116/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1883 - acc: 0.9252 - val_loss: 0.1007 - val_acc: 0.9803\n",
      "Epoch 117/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.1901 - acc: 0.9248 - val_loss: 0.1032 - val_acc: 0.9810\n",
      "Epoch 118/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1877 - acc: 0.9262 - val_loss: 0.1033 - val_acc: 0.9809\n",
      "Epoch 119/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1840 - acc: 0.9267 - val_loss: 0.1038 - val_acc: 0.9811\n",
      "Epoch 120/10000\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.1844 - acc: 0.9266 - val_loss: 0.1024 - val_acc: 0.9820\n",
      "Epoch 121/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1815 - acc: 0.9291 - val_loss: 0.1038 - val_acc: 0.9814\n",
      "Epoch 122/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1825 - acc: 0.9280 - val_loss: 0.1037 - val_acc: 0.9809\n",
      "Epoch 123/10000\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.1841 - acc: 0.9276 - val_loss: 0.1034 - val_acc: 0.9804\n",
      "Epoch 124/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.1795 - acc: 0.9295 - val_loss: 0.1039 - val_acc: 0.9812\n",
      "Epoch 125/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1864 - acc: 0.9272 - val_loss: 0.1041 - val_acc: 0.9812\n",
      "Epoch 126/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1827 - acc: 0.9284 - val_loss: 0.1037 - val_acc: 0.9804\n",
      "Epoch 127/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1838 - acc: 0.9282 - val_loss: 0.1062 - val_acc: 0.9802\n",
      "Epoch 128/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1753 - acc: 0.9303 - val_loss: 0.1064 - val_acc: 0.9801\n",
      "Epoch 129/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1765 - acc: 0.9303 - val_loss: 0.1084 - val_acc: 0.9805\n",
      "Epoch 130/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1791 - acc: 0.9307 - val_loss: 0.1059 - val_acc: 0.9811\n",
      "Epoch 131/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1797 - acc: 0.9291 - val_loss: 0.1052 - val_acc: 0.9805\n",
      "Epoch 132/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.1754 - acc: 0.9299 - val_loss: 0.1036 - val_acc: 0.9808\n",
      "Epoch 133/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1771 - acc: 0.9293 - val_loss: 0.1044 - val_acc: 0.9804\n",
      "Epoch 134/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1727 - acc: 0.9308 - val_loss: 0.1039 - val_acc: 0.9811\n",
      "Epoch 135/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1758 - acc: 0.9294 - val_loss: 0.1071 - val_acc: 0.9812\n",
      "Epoch 136/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.1733 - acc: 0.9330 - val_loss: 0.1042 - val_acc: 0.9806\n",
      "Epoch 137/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1759 - acc: 0.9303 - val_loss: 0.1046 - val_acc: 0.9812\n",
      "Epoch 138/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1763 - acc: 0.9309 - val_loss: 0.1077 - val_acc: 0.9804\n",
      "Epoch 139/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1718 - acc: 0.9320 - val_loss: 0.1074 - val_acc: 0.9811\n",
      "Epoch 140/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1743 - acc: 0.9318 - val_loss: 0.1062 - val_acc: 0.9807\n",
      "Epoch 141/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1734 - acc: 0.9311 - val_loss: 0.1072 - val_acc: 0.9806\n",
      "Epoch 142/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1722 - acc: 0.9313 - val_loss: 0.1089 - val_acc: 0.9805\n",
      "Epoch 143/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1720 - acc: 0.9311 - val_loss: 0.1085 - val_acc: 0.9805\n",
      "Epoch 144/10000\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.1729 - acc: 0.9308 - val_loss: 0.1054 - val_acc: 0.9800\n",
      "Epoch 145/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1734 - acc: 0.9300 - val_loss: 0.1068 - val_acc: 0.9812\n",
      "Epoch 146/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1679 - acc: 0.9323 - val_loss: 0.1088 - val_acc: 0.9807\n",
      "Epoch 147/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1670 - acc: 0.9315 - val_loss: 0.1075 - val_acc: 0.9816\n",
      "Epoch 148/10000\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 0.1679 - acc: 0.9325 - val_loss: 0.1103 - val_acc: 0.9811\n",
      "Epoch 149/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1710 - acc: 0.9301 - val_loss: 0.1090 - val_acc: 0.9798\n",
      "Epoch 150/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1657 - acc: 0.9336 - val_loss: 0.1091 - val_acc: 0.9810\n",
      "Epoch 151/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1662 - acc: 0.9323 - val_loss: 0.1105 - val_acc: 0.9802\n",
      "Epoch 152/10000\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 0.1677 - acc: 0.9312 - val_loss: 0.1133 - val_acc: 0.9802\n",
      "Epoch 153/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1717 - acc: 0.9310 - val_loss: 0.1108 - val_acc: 0.9809\n",
      "Epoch 154/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1695 - acc: 0.9313 - val_loss: 0.1105 - val_acc: 0.9812\n",
      "Epoch 155/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1713 - acc: 0.9320 - val_loss: 0.1115 - val_acc: 0.9808\n",
      "Epoch 156/10000\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 0.1697 - acc: 0.9321 - val_loss: 0.1122 - val_acc: 0.9801\n",
      "Epoch 157/10000\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 0.1661 - acc: 0.9335 - val_loss: 0.1158 - val_acc: 0.9800\n",
      "Epoch 158/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1628 - acc: 0.9347 - val_loss: 0.1122 - val_acc: 0.9802\n",
      "Epoch 159/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.1603 - acc: 0.9352 - val_loss: 0.1128 - val_acc: 0.9806\n",
      "Epoch 160/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1681 - acc: 0.9315 - val_loss: 0.1119 - val_acc: 0.9806\n",
      "Epoch 161/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1646 - acc: 0.9321 - val_loss: 0.1125 - val_acc: 0.9810\n",
      "Epoch 162/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1637 - acc: 0.9316 - val_loss: 0.1133 - val_acc: 0.9807\n",
      "Epoch 163/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1615 - acc: 0.9343 - val_loss: 0.1125 - val_acc: 0.9797\n",
      "Epoch 164/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1645 - acc: 0.9325 - val_loss: 0.1157 - val_acc: 0.9801\n",
      "Epoch 165/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1643 - acc: 0.9316 - val_loss: 0.1164 - val_acc: 0.9788\n",
      "Epoch 166/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1631 - acc: 0.9329 - val_loss: 0.1115 - val_acc: 0.9806\n",
      "Epoch 167/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1614 - acc: 0.9329 - val_loss: 0.1144 - val_acc: 0.9802\n",
      "Epoch 168/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1631 - acc: 0.9323 - val_loss: 0.1156 - val_acc: 0.9800\n",
      "Epoch 169/10000\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1636 - acc: 0.9322 - val_loss: 0.1170 - val_acc: 0.9797\n",
      "Epoch 170/10000\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.1633 - acc: 0.9327 - val_loss: 0.1136 - val_acc: 0.9803\n",
      "Epoch 171/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1660 - acc: 0.9311 - val_loss: 0.1124 - val_acc: 0.9801\n",
      "Epoch 172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 108us/step - loss: 0.1611 - acc: 0.9344 - val_loss: 0.1141 - val_acc: 0.9805\n",
      "Epoch 173/10000\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.1609 - acc: 0.9328 - val_loss: 0.1183 - val_acc: 0.9805\n",
      "Epoch 174/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1581 - acc: 0.9342 - val_loss: 0.1151 - val_acc: 0.9798\n",
      "Epoch 175/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1644 - acc: 0.9325 - val_loss: 0.1120 - val_acc: 0.9808\n",
      "Epoch 176/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1600 - acc: 0.9343 - val_loss: 0.1161 - val_acc: 0.9804\n",
      "Epoch 177/10000\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 0.1610 - acc: 0.9324 - val_loss: 0.1171 - val_acc: 0.9796\n",
      "Epoch 178/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1614 - acc: 0.9326 - val_loss: 0.1153 - val_acc: 0.9799\n",
      "Epoch 179/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1631 - acc: 0.9299 - val_loss: 0.1150 - val_acc: 0.9808\n",
      "Epoch 180/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1654 - acc: 0.9306 - val_loss: 0.1195 - val_acc: 0.9802\n",
      "Epoch 181/10000\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 0.1589 - acc: 0.9339 - val_loss: 0.1191 - val_acc: 0.9805\n",
      "Epoch 182/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1623 - acc: 0.9326 - val_loss: 0.1196 - val_acc: 0.9801\n",
      "Epoch 183/10000\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 0.1589 - acc: 0.9344 - val_loss: 0.1208 - val_acc: 0.9802\n",
      "Epoch 184/10000\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.1581 - acc: 0.9337 - val_loss: 0.1181 - val_acc: 0.9802\n",
      "Epoch 185/10000\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 0.1577 - acc: 0.9340 - val_loss: 0.1191 - val_acc: 0.9805\n",
      "Epoch 186/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1585 - acc: 0.9316 - val_loss: 0.1165 - val_acc: 0.9802\n",
      "Epoch 187/10000\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.1622 - acc: 0.9321 - val_loss: 0.1178 - val_acc: 0.9805\n",
      "Epoch 188/10000\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 0.1563 - acc: 0.9339 - val_loss: 0.1172 - val_acc: 0.9805\n",
      "Epoch 189/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1540 - acc: 0.9342 - val_loss: 0.1188 - val_acc: 0.9806\n",
      "Epoch 190/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1569 - acc: 0.9341 - val_loss: 0.1176 - val_acc: 0.9803\n",
      "Epoch 191/10000\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 0.1578 - acc: 0.9323 - val_loss: 0.1192 - val_acc: 0.9807\n",
      "Epoch 192/10000\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.1569 - acc: 0.9322 - val_loss: 0.1195 - val_acc: 0.9808\n",
      "Epoch 193/10000\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.1556 - acc: 0.9337 - val_loss: 0.1190 - val_acc: 0.9815\n",
      "Epoch 194/10000\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.1573 - acc: 0.9328 - val_loss: 0.1184 - val_acc: 0.9806\n",
      "Epoch 195/10000\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.1545 - acc: 0.9345 - val_loss: 0.1205 - val_acc: 0.9802\n",
      "Epoch 196/10000\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 0.1535 - acc: 0.9352 - val_loss: 0.1175 - val_acc: 0.9811\n",
      "Epoch 197/10000\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 0.1570 - acc: 0.9330 - val_loss: 0.1207 - val_acc: 0.9799\n",
      "Epoch 00197: early stopping\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 10000\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 32\n",
    "early_patience = 100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "trainingtarget1 = to_categorical(trainingtarget, 10)\n",
    "valtarget1 = to_categorical(valtarget,10)\n",
    "\n",
    "history = model.fit(trainingdata\n",
    "                    , trainingtarget1\n",
    "                    , validation_split=0.2\n",
    "                    , validation_data=(valdata,valtarget1)\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x0000022085969550>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000220849F5358>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000022084A32A58>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000022084A76C88>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtarget1 = to_categorical(testtarget,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = model.predict(testdata)\n",
    "testing = np.argmax(testing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range (0,len(testing)):\n",
    "    if(testing[i] == testtarget[i]):\n",
    "        counter += 1\n",
    "acc_nn = (counter/len(testing))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  97.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_nn,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 968,    1,    0,    0,    0,    0,    7,    0,    3,    1],\n",
       "       [   0, 1124,    2,    1,    0,    0,    1,    0,    7,    0],\n",
       "       [   1,    0, 1007,    2,    3,    0,    2,    9,    8,    0],\n",
       "       [   0,    0,    3,  988,    0,    8,    0,    2,    7,    2],\n",
       "       [   0,    0,    0,    0,  960,    0,    7,    1,    1,   13],\n",
       "       [   3,    0,    0,   10,    0,  865,    5,    0,    7,    2],\n",
       "       [   4,    2,    0,    0,    6,    2,  942,    0,    2,    0],\n",
       "       [   0,    1,   10,    1,    0,    0,    0, 1008,    4,    4],\n",
       "       [   0,    1,    2,    5,    6,    3,    1,    1,  952,    3],\n",
       "       [   2,    3,    0,    6,   11,    3,    1,    3,    2,  978]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = testtarget\n",
    "y_pred = testing\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.97      0.98      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.96      0.98      0.97       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testtarget, testing)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist2 = np.asarray(y_pred) #-------------------------------> MNIST prediction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat = np.asarray(USPSMat)\n",
    "testing = model.predict(USPSMat)\n",
    "testing1 = np.argmax(testing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range (0,len(testing)):\n",
    "    if(testing1[i] == USPSTar[i]):\n",
    "        counter += 1\n",
    "acc_nn2 = (counter/len(testing))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  45.7323\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_nn2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 810,   34,   49,  181,  136,  271,   82,   62,   73,  302],\n",
       "       [  37,  488,  248,  105,  437,   80,    8,  207,  285,  105],\n",
       "       [  69,   31, 1434,   79,   11,   87,   52,   41,  186,    9],\n",
       "       [  17,   11,   48, 1588,    5,  175,    1,   16,  129,   10],\n",
       "       [  34,  190,   23,   44, 1157,   65,   31,  115,  273,   68],\n",
       "       [ 162,   24,   54,  394,    4, 1139,   38,   28,  141,   16],\n",
       "       [ 336,   15,  325,   43,   36,  147,  943,   50,   81,   24],\n",
       "       [  34,  128,  170,  641,   61,   27,    6,  589,  272,   72],\n",
       "       [ 135,   32,   49,  536,   57,  344,   72,   44,  672,   59],\n",
       "       [  14,  130,   72,  388,  146,   29,    5,  500,  390,  326]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = USPSTar\n",
    "y_pred = testing1\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.41      0.44      2000\n",
      "           1       0.45      0.24      0.32      2000\n",
      "           2       0.58      0.72      0.64      1999\n",
      "           3       0.40      0.79      0.53      2000\n",
      "           4       0.56      0.58      0.57      2000\n",
      "           5       0.48      0.57      0.52      2000\n",
      "           6       0.76      0.47      0.58      2000\n",
      "           7       0.36      0.29      0.32      2000\n",
      "           8       0.27      0.34      0.30      2000\n",
      "           9       0.33      0.16      0.22      2000\n",
      "\n",
      "   micro avg       0.46      0.46      0.46     19999\n",
      "   macro avg       0.47      0.46      0.44     19999\n",
      "weighted avg       0.47      0.46      0.44     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(USPSTar, testing1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps2 = testing1 #-------------------------------> USPS prediction 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(trainingdata, trainingtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target1 = svclassifier.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range (0,len(testtarget)):\n",
    "    if(pred_target1[i] == testtarget[i]):\n",
    "        counter += 1\n",
    "acc_svm = (counter/len(testtarget))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  93.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_svm,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 959    0    5    2    2    4    7    0    1    0]\n",
      " [   0 1121    3    3    0    1    2    1    4    0]\n",
      " [   6    8  968    9    3    2   11   10   13    2]\n",
      " [   5    2   17  944    4   13    1    8   13    3]\n",
      " [   2    1   10    1  943    0    4    2    2   17]\n",
      " [  13    4    2   39    5  792    9    1   22    5]\n",
      " [  10    3   11    1    5   14  911    2    1    0]\n",
      " [   1    8   20   10    6    1    0  961    3   18]\n",
      " [   8    4    9   25   11   27    6    5  871    8]\n",
      " [   7    6    2   13   32    4    0   18    7  920]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(testtarget, pred_target1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       980\n",
      "           1       0.97      0.99      0.98      1135\n",
      "           2       0.92      0.94      0.93      1032\n",
      "           3       0.90      0.93      0.92      1010\n",
      "           4       0.93      0.96      0.95       982\n",
      "           5       0.92      0.89      0.91       892\n",
      "           6       0.96      0.95      0.95       958\n",
      "           7       0.95      0.93      0.94      1028\n",
      "           8       0.93      0.89      0.91       974\n",
      "           9       0.95      0.91      0.93      1009\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testtarget, pred_target1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist3 = np.asarray(pred_target1) #-------------------------------> MNIST prediction 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target = svclassifier.predict(USPSMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range (0,len(USPSTar)):\n",
    "    if(pred_target[i] == USPSTar[i]):\n",
    "        counter += 1\n",
    "acc_svm1 = (counter/len(USPSTar))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  29.1265\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_svm1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 348    0  476  152  222  345   74  172   10  201]\n",
      " [  60  303  534  275  230  172   17  351   37   21]\n",
      " [ 139   63 1293  115   33  221   55   45   21   14]\n",
      " [  56   58  341  898    8  520    9   45   48   17]\n",
      " [  24   24  221   82  800  215   10  464   82   78]\n",
      " [  47   25  652  240   41  876   30   35   41   13]\n",
      " [ 146   19  903   55   86  264  462   38    2   25]\n",
      " [  19   74  201  706   54  294   12  522   84   34]\n",
      " [ 100   16  298  449  126  692   82   58  160   19]\n",
      " [  18   38  204  588  142  104    8  580  155  163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(USPSTar, pred_target))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.17      0.24      2000\n",
      "           1       0.49      0.15      0.23      2000\n",
      "           2       0.25      0.65      0.36      1999\n",
      "           3       0.25      0.45      0.32      2000\n",
      "           4       0.46      0.40      0.43      2000\n",
      "           5       0.24      0.44      0.31      2000\n",
      "           6       0.61      0.23      0.33      2000\n",
      "           7       0.23      0.26      0.24      2000\n",
      "           8       0.25      0.08      0.12      2000\n",
      "           9       0.28      0.08      0.13      2000\n",
      "\n",
      "   micro avg       0.29      0.29      0.29     19999\n",
      "   macro avg       0.34      0.29      0.27     19999\n",
      "weighted avg       0.34      0.29      0.27     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(USPSTar, pred_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps3 = np.asarray(pred_target) #-------------------------------> USPS prediction 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=500)\n",
    "rfc.fit(trainingdata, trainingtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rfc.predict(testdata)\n",
    "predicted_m = np.argmax(predicted, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range (len(testtarget)):\n",
    "    if(predicted_m[i] == testtarget[i]):\n",
    "        count += 1\n",
    "acc_rfc = ((count/len(testtarget))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  90.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_rfc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 979,    0,    0,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [  24, 1109,    0,    1,    0,    0,    1,    0,    0,    0],\n",
       "       [ 102,    0,  923,    0,    0,    0,    2,    4,    1,    0],\n",
       "       [ 130,    0,    1,  874,    0,    2,    0,    3,    0,    0],\n",
       "       [ 107,    0,    0,    0,  869,    0,    0,    0,    1,    5],\n",
       "       [ 132,    0,    0,    1,    0,  758,    1,    0,    0,    0],\n",
       "       [  64,    2,    0,    0,    1,    0,  891,    0,    0,    0],\n",
       "       [  90,    0,    8,    0,    0,    0,    0,  929,    0,    1],\n",
       "       [ 160,    0,    0,    0,    1,    0,    0,    0,  811,    2],\n",
       "       [ 118,    0,    0,    0,    3,    0,    0,    1,    0,  887]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = testtarget\n",
    "y_pred = predicted_m\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68       980\n",
      "           1       1.00      0.98      0.99      1135\n",
      "           2       0.99      0.89      0.94      1032\n",
      "           3       1.00      0.87      0.93      1010\n",
      "           4       0.99      0.88      0.94       982\n",
      "           5       1.00      0.85      0.92       892\n",
      "           6       1.00      0.93      0.96       958\n",
      "           7       0.99      0.90      0.95      1028\n",
      "           8       1.00      0.83      0.91       974\n",
      "           9       0.99      0.88      0.93      1009\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10000\n",
      "   macro avg       0.95      0.90      0.91     10000\n",
      "weighted avg       0.95      0.90      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testtarget, predicted_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist4 = np.asarray(predicted_m) #-------------------------------> MNIST prediction 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999\n",
      "19999\n"
     ]
    }
   ],
   "source": [
    "predicted_u = rfc.predict(USPSMat)\n",
    "predicted_u = np.argmax(predicted_u, axis =1)\n",
    "print(len(predicted_u))\n",
    "print(len(USPSTar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range (len(USPSTar)):\n",
    "    if(predicted_u[i] == USPSTar[i]):\n",
    "        count += 1\n",
    "acc_rfc_usps = ((count/len(USPSTar))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy ----->  14.9707\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy ----->  \"+ str(np.around(acc_rfc_usps,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1987,    0,    3,    0,    6,    0,    0,    0,    0,    4],\n",
       "       [1499,  220,    0,    0,    0,    0,    1,  280,    0,    0],\n",
       "       [1899,    0,   85,    0,    0,    0,    0,   15,    0,    0],\n",
       "       [1876,    0,    0,  124,    0,    0,    0,    0,    0,    0],\n",
       "       [1727,    5,    0,    0,  205,    0,    0,   63,    0,    0],\n",
       "       [1876,    0,    0,    0,    0,  123,    0,    1,    0,    0],\n",
       "       [1960,    1,    0,    0,    0,    0,   39,    0,    0,    0],\n",
       "       [1757,   34,    2,    0,    0,    0,    0,  207,    0,    0],\n",
       "       [1995,    0,    0,    0,    0,    2,    0,    0,    3,    0],\n",
       "       [1952,   11,    0,    0,    0,    0,    0,   36,    0,    1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = USPSTar\n",
    "y_pred = predicted_u\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.99      0.19      2000\n",
      "           1       0.81      0.11      0.19      2000\n",
      "           2       0.94      0.04      0.08      1999\n",
      "           3       1.00      0.06      0.12      2000\n",
      "           4       0.97      0.10      0.19      2000\n",
      "           5       0.98      0.06      0.12      2000\n",
      "           6       0.97      0.02      0.04      2000\n",
      "           7       0.34      0.10      0.16      2000\n",
      "           8       1.00      0.00      0.00      2000\n",
      "           9       0.20      0.00      0.00      2000\n",
      "\n",
      "   micro avg       0.15      0.15      0.15     19999\n",
      "   macro avg       0.73      0.15      0.11     19999\n",
      "weighted avg       0.73      0.15      0.11     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(USPSTar, predicted_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "usps4 = np.asarray(predicted_u) #-------------------------------> USPS prediction 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft-Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1) (10000,) (10000,) (10000,) (19999,) (19999,) (19999,) (19999,)\n",
      "10000 19999\n"
     ]
    }
   ],
   "source": [
    "print(mnist1.shape, mnist2.shape, mnist3.shape, mnist4.shape, usps1.shape, usps2.shape, usps3.shape, usps4.shape)\n",
    "\n",
    "r1 = mnist1.shape[0]\n",
    "r2 =  usps1.shape[0]\n",
    "\n",
    "print(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_matrix = np.ones(10)\n",
    "\n",
    "final_pred_target_mnist = np.zeros((r1,1))\n",
    "\n",
    "for i in range(1, len(mnist1)):\n",
    "    i1 = mnist1[i]\n",
    "    i2 = mnist2[i]\n",
    "    i3 = mnist3[i]\n",
    "    i4 = mnist4[i]\n",
    "    class_matrix[i1] += 1\n",
    "    class_matrix[i2] += 1\n",
    "    class_matrix[i3] += 1\n",
    "    class_matrix[i4] += 1\n",
    "    y = np.argmax(class_matrix)\n",
    "    final_pred_target_mnist[i] = y\n",
    "    class_matrix = np.ones(10)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range (0,len(testtarget)):\n",
    "    if(final_pred_target_mnist[i] == testtarget[i]):\n",
    "        counter += 1\n",
    "final_acc_mnist = (counter/len(testtarget))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_matrix_usps = np.ones(10)\n",
    "\n",
    "final_pred_target_usps = np.zeros((r2,1))\n",
    "\n",
    "for i in range(1, len(USPSTar)):\n",
    "    i1 = usps1[i]\n",
    "    i2 = usps2[i]\n",
    "    i3 = usps3[i]\n",
    "    i4 = usps4[i]\n",
    "    class_matrix[i1] += 1\n",
    "    class_matrix[i2] += 1\n",
    "    class_matrix[i3] += 1\n",
    "    class_matrix[i4] += 1\n",
    "    y = np.argmax(class_matrix)\n",
    "    final_pred_target_usps[i] = y\n",
    "    class_matrix = np.ones(10)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range (0,len(USPSTar)):\n",
    "    if(final_pred_target_usps[i] == USPSTar[i]):\n",
    "        counter += 1\n",
    "final_acc_usps = (counter/len(USPSTar))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Accuracy on MNIST after Soft-Voting ----->  90.47\n",
      "Merged Accuracy on MNIST after Soft-Voting ----->  37.8119\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged Accuracy on MNIST after Soft-Voting ----->  \"+ str(np.around(final_acc_mnist,4)))\n",
    "print(\"Merged Accuracy on MNIST after Soft-Voting ----->  \"+ str(np.around(final_acc_usps,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
